{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Category distribution .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu2I_zFueXyb"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIuZvXxtEsAI"
      },
      "source": [
        "!echo spark.driver.memory 5g  > /content/spark-2.4.7-bin-hadoop2.7/conf/spark-defaults.conf\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF5Qk7jFeYcj"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SQLContext \n",
        "from pyspark import SparkContext \n",
        "sc =SparkContext()\n",
        "sqlContext = SQLContext(sc)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VirCwO5bS9LC"
      },
      "source": [
        "from pyspark.sql.functions import col, concat_ws , monotonically_increasing_id\n",
        "\n",
        "from pyspark.ml.feature import CountVectorizer ,Tokenizer ,StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import numpy as np\n",
        "from pyspark.sql.functions import *\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Va-RFqeS0C4"
      },
      "source": [
        "### Data cleaning and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDrZTSKYXqCB"
      },
      "source": [
        "toknizer = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "combined_pat = r'|'.join((pat1, pat2))\n",
        "\n",
        "def data_cleaner(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped_text = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped_text)\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lowercase = letters.lower()\n",
        "    words = toknizer.tokenize(lowercase)\n",
        "    return (\" \".join(words)).strip()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_XDxOVdfUF8"
      },
      "source": [
        "API_comment_cat = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/content/drive/Shareddrives/YT-data/catagorical.csv')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HpmTzbQpSUh"
      },
      "source": [
        "drop_list = [\"likes\"  ,\"replies\"]\n",
        "API_comment_cat = API_comment_cat.select([column for column in API_comment_cat.columns if column not in drop_list])\n",
        "API_comment_cat = API_comment_cat.withColumn(\"comment_text\", concat_ws(\",\",col(\"comment_text\")))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df-ERjlyYEPz"
      },
      "source": [
        "API_comment_cat = API_comment_cat.rdd.map(lambda x : ( x[0] , x[1] , data_cleaner(x[2])) ).toDF().selectExpr( \"_1 as video_id\",\"_2 as category_id\" ,\"_3 as comment_text\")\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sycjXxuZ-NzX"
      },
      "source": [
        "API_comment_cat = API_comment_cat.withColumn(\"_id\", monotonically_increasing_id())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiPEaXxVTOQn"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxpZGz0LkFRM"
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"tokens\")\n",
        "\n",
        "c_v = CountVectorizer(vocabSize=3000 , inputCol=\"tokens\", outputCol=\"features\")\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"category_id\", outputCol=\"label\")\n",
        "\n",
        "LR_classifier = LogisticRegression(family=\"multinomial\")\n",
        "\n",
        "LR_classifier_pipeline = Pipeline(stages=[tokenizer, c_v , indexer ,LR_classifier])\n",
        "\n",
        "model = LR_classifier_pipeline.fit(API_comment_cat.limit(240000))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJK8_tl3kqz0"
      },
      "source": [
        "train_predictions= model.transform(API_comment_cat.limit(240000))\n",
        "lr_model_evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "train_accuracy = lr_model_evaluator.evaluate(train_predictions)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9PTY0C-lA97"
      },
      "source": [
        "print(\"Accuracy = %g\" % (train_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "806t6kY9vT3T"
      },
      "source": [
        "# Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBJn2yoLlBbY"
      },
      "source": [
        "test_set = API_comment_cat.filter ((API_comment_cat._id > 240000 ) & (API_comment_cat._id < 300000) )\n",
        "test_set = test_set.where(test_set.category_id.isin([24 , 22 , 17 , 10 , 28 , 1 , 2 , 15 , 17 , 18   ,20 ,23 ,25 ,26 ,27]))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EObPqC5-U1M3"
      },
      "source": [
        "test_predictions =  model.transform(test_set)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXnc4vqpzntq"
      },
      "source": [
        "lr_model_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "test_accuracy = lr_model_evaluator.evaluate(test_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_c4qPUoVQ3J"
      },
      "source": [
        "print(\"Accuracy = %g\" % (test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZEbmjpDTedl"
      },
      "source": [
        "## Video cateogry distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVShAOLtjuhr"
      },
      "source": [
        "vid_prob= LR_predictions.rdd.map(lambda row : (row[\"video_id\"],row[\"probability\"]) ).reduceByKey( lambda x , y : x + y)\n",
        "vid_count= LR_predictions.rdd.map(lambda row : (row[\"video_id\"],1) ).reduceByKey( lambda x , y : x + y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsPD5Fr_BCri"
      },
      "source": [
        "vid_prob_count = vid_prob.join(vid_count)\n",
        "vid_cat_dist= vid_prob_count.map(lambda row : (row[0] , row[1][0]/ row[1][1] ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G78SSITJ9dTn"
      },
      "source": [
        "## Comment cateogry distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRoulNoKwIBw"
      },
      "source": [
        "comment_cat_dist = LR_predictions.rdd.map(lambda row : (row[\"comment_text\"],row[\"probability\"]) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwRpl9N3cou0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}